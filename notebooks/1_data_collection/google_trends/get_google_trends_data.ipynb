{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose\n",
    "This notebook serves to contact Pytrends API and retrieve relative popularities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pytrends.request import TrendReq\n",
    "import time\n",
    "from time import sleep\n",
    "from random import randint\n",
    "import random\n",
    "import calendar\n",
    "import time\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytrends = TrendReq(timeout=None, retries=10, backoff_factor=0.5)\n",
    "batch_size = 4\n",
    "predefined_element = \"air travel\"\n",
    "unique_tags = []\n",
    "i = -4 # Initial value is -4\n",
    "## TODO Get your keywords from the csv files you have saved\n",
    "#file_path = r\"C:\\School\\Semester_1\\Data_Wrangling\\Data_in_the_wild_exam\\data\\intermediate\\pytrends\\auxiliary\\2022\\missing_pytrends_tags_2022.csv\"\n",
    "#df = pd.read_csv(file_path, sep=';')\n",
    "#for ind in df.index:\n",
    "#    unique_tags.append(df['tag'][ind])\n",
    "unique_tags = ['horses', 'horse']\n",
    "while i <= len(unique_tags) - 1:\n",
    "    try:\n",
    "        i += batch_size\n",
    "        if i + batch_size > len(unique_tags) - 1:\n",
    "             batch = unique_tags[i : len(unique_tags) - 1]\n",
    "        else:\n",
    "            batch = unique_tags[i : i + batch_size]\n",
    "        # Add the pre-defined element\n",
    "        batch.append(predefined_element)\n",
    "        \n",
    "        print(f'This is my batch {i} - {i+4}'.format(i=i))\n",
    "        ## TODO Replace with your parameters\n",
    "        pytrends.build_payload(batch, timeframe='2023-01-01 2023-01-31', geo='GB')\n",
    "        response = pytrends.interest_over_time()\n",
    "\n",
    "        current_GMT = time.gmtime()\n",
    "        time_stamp = calendar.timegm(current_GMT)\n",
    "        ## TODO replace with your path\n",
    "        response.to_csv(f'C:\\School\\Semester_1\\Data_Wrangling\\Data_in_the_wild_exam\\data\\\\raw\\pytrends\\\\raw_results_2022\\{time_stamp}_keywords.csv', sep=\";\")\n",
    "\n",
    "        # Wait a little so I don't overwhelm the API with requests\n",
    "        sleep(randint(5, 18))\n",
    "        \n",
    "        if i + batch_size > len(unique_tags) - 1:\n",
    "            raise KeyError('done')\n",
    "        \n",
    "    except KeyError as error:\n",
    "        print('Done! You can empty the leftover csv!')\n",
    "        with open(r\"C:\\School\\Semester_1\\Data_Wrangling\\Data_in_the_wild_exam\\data\\intermediate\\pytrends\\auxiliary\\2022\\leftover_tags.csv\", \"x\", encoding='utf-8', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Empty! We are done!'])  # Write header\n",
    "\n",
    "    ## It is common to get 429 exceptions from the API. In case we do get one,\n",
    "    # we will interrupt the scraping for a while, saving our progress in a csv\n",
    "    # After a while we shuffle the remaining tags to ensure that the request is random\n",
    "    # This is done so that we don't repeat the same request, which is seemingly treated as suspicious by Google    \n",
    "    except Exception as error:\n",
    "            print(f'The request failed at batch {i} - {i+4}'.format(i=i))\n",
    "            print('Noting the last index of the failed request')\n",
    "            display(error)\n",
    "\n",
    "            # Write the index to the file\n",
    "            with open(r\"C:\\School\\Semester_1\\Data_Wrangling\\Data_in_the_wild_exam\\data\\intermediate\\pytrends\\auxiliary\\2022\\failed_requests_index.txt\", \"x\") as file:\n",
    "                file.write(str(i))\n",
    "\n",
    "            # Slice the unique_tags array based on the index\n",
    "            unique_tags = unique_tags[i:]\n",
    "            print(unique_tags)\n",
    "            # TODO replace with your path\n",
    "            with open(r\"C:\\School\\Semester_1\\Data_Wrangling\\Data_in_the_wild_exam\\data\\intermediate\\pytrends\\auxiliary\\2022\\leftover_tags.csv\", \"w\") as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([\"tag\"])  # Write header\n",
    "                for tag in unique_tags:\n",
    "                    writer.writerow([tag])\n",
    "\n",
    "            #Reset i == -4.\n",
    "            i = -4\n",
    "\n",
    "            #Shuffle the array so we send random elements to confuse the API\n",
    "            random.shuffle(unique_tags)\n",
    "            sleep(randint(10, 15))\n",
    "\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For testing\n",
    "Some code with dummy arrays to simulate the requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checksum = 0\n",
    "pytrends = TrendReq(timeout=None, retries=10, backoff_factor=0.5)\n",
    "batch_size = 4\n",
    "predefined_element = \"air travel\"\n",
    "unique_tags = []\n",
    "i = -4 # modify this value depending on progress\n",
    "file_path = r\"C:\\School\\Semester_1\\Data_Wrangling\\Data_in_the_wild_exam\\data\\intermediate\\pytrends\\auxiliary\\2022\\missing_pytrends_tags_2022.csv\"\n",
    "df = pd.read_csv(file_path, sep=';')\n",
    "for ind in df.index:\n",
    "    unique_tags.append(df['tag'][ind])\n",
    "print(unique_tags)\n",
    "while i <= len(unique_tags) - 1:\n",
    "    try:\n",
    "        i += batch_size\n",
    "        checksum += 1\n",
    "        print(i, len(unique_tags))\n",
    "        if i + batch_size > len(unique_tags) - 1:\n",
    "             batch = unique_tags[i : len(unique_tags) - 1]\n",
    "        else:\n",
    "            batch = unique_tags[i : i + batch_size]\n",
    "        # Add the pre-defined element\n",
    "        batch.append(predefined_element)\n",
    "        \n",
    "        print(f'This is my batch {i} - {i+4}'.format(i=i))\n",
    "        print(batch)\n",
    "\n",
    "        # Wait a little so I don't overwhelm the API with requests\n",
    "        #make request\n",
    "        #make the csv file with response\n",
    "        #sleep(randint(5, 18))\n",
    "        print('Sending request and simulating sleep!! ZZzzzzzZZZzzz')\n",
    "\n",
    "        if i + batch_size > len(unique_tags) - 1:\n",
    "            raise KeyError('done')\n",
    "\n",
    "        if i > 10:\n",
    "            raise Exception('Dummy exception at third req!!')\n",
    "        \n",
    "        \n",
    "    except KeyError as error:\n",
    "        print('Done! You can empty the leftover csv!')\n",
    "        with open(\"leftover_tags.csv\", \"w\", encoding='utf-8', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Empty! We are done!'])  # Write header\n",
    "        \n",
    "    except Exception as error:\n",
    "            print(f'The request failed at batch {i} - {i+4}'.format(i=i))\n",
    "            print('Noting the last index of the failed request')\n",
    "\n",
    "            # Write the index to the file\n",
    "            with open(\"failed_requests_index.txt\", \"w\") as file:\n",
    "                file.write(str(i))\n",
    "\n",
    "            # Slice the unique_tags array based on the index\n",
    "            unique_tags = unique_tags[i:]\n",
    "            print(unique_tags)\n",
    "\n",
    "            with open(\"leftover_tags.csv\", \"w\", encoding='utf-8', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([\"tag\"])  # Write header\n",
    "                for tag in unique_tags:\n",
    "                    writer.writerow([tag])\n",
    "\n",
    "            #Reset i == -4.\n",
    "            i = -4\n",
    "\n",
    "            #Shuffle the array so we send random elements to confuse the API\n",
    "            random.shuffle(unique_tags)\n",
    "\n",
    "            continue\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
