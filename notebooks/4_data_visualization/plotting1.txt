# Load the CSV file
df = pd.read_csv('2022_df_normalized_results_score_avg.csv', sep=';')

# Convert the 'Date' column to datetime
df['Date'] = pd.to_datetime(df['Date'])

# Filter the DataFrame for the specific category
category = "sports" # set the category to filter for here
df_categorized = df[df['Chat GPT'] == category]

# Group by the 'Date' column and calculate the average score
df_score = df_categorized.groupby(df_categorized['Date'])['avg_score'].mean().reset_index()
# Group by the 'Date' column and count the frequency
df_freq = df_categorized.groupby(df_categorized['Date']).size().reset_index(name='Frequency')
# normalize the values for avg_score and frequency on a scale from 0-100
def min_max_scaling(x, min_val, max_val):
    return ((x - min_val) / (max_val - min_val)) * 100
frequency_column = 'Frequency'
avg_column = "avg_score"
df_freq[frequency_column + '_normalized'] = min_max_scaling(df_freq[frequency_column], df_freq[frequency_column].min(), df_freq[frequency_column].max())
df_score[avg_column + '_normalized'] = min_max_scaling(df_score[avg_column], df_score[avg_column].min(), df_score[avg_column].max())
# plot the data
#plt.style.use('seaborn-v0_8-deep')
plt.style.use('default')
ax = df_score.plot(x = "Date", y = "avg_score_normalized")
df_freq.plot(x="Date", y = "Frequency_normalized", ax = ax)
ax.set_title("Relationship between amount of articles and popularity in " +  category)
ax.set_ylabel("min/max over period")