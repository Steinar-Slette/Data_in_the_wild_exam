{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from time import sleep\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "  api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"2022-01_skynews_articles.csv\", sep=';')\n",
    "\n",
    "df.dropna(subset=['Tags'], inplace=True)\n",
    "df_first = df.drop(df[df['Tags'] == \"['N/A']\"].index)\n",
    "df_second = df_first.drop(df_first[df_first['Tags'] == \"[]\"].index)\n",
    "\n",
    "df_second.to_csv(\"01_skynews_articles_clean.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82, 11)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"2022_skynews_articles_clean_part5.csv\", sep=';')\n",
    "df = df.reset_index()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_res(batch):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You will be provided with a batch of items. Each item consists of a title and one or multiple tags that both belong to one news article. The items start with <itemStart> and end with <itemEnd>. Your task is to classify the topic of a news article by looking at its title and tags in either politics, business and economy, environment, sports, entertainment and culture, science and technology or health. Return only the number of the Article and its category separated with a whitespace in a python list where the result matches the order of the input.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{batch}\"}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    categories = response.choices[0].message.content[1:-1].split(\",\")\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "[\"'ARTICLE-1: politics'\", \" 'ARTICLE-2: health'\", \" 'ARTICLE-3: politics'\", \" 'ARTICLE-4: health'\", \" 'ARTICLE-5: politics'\", \" 'ARTICLE-6: politics'\", \" 'ARTICLE-7: health'\", \" 'ARTICLE-8: politics'\", \" 'ARTICLE-9: politics'\", \" 'ARTICLE-10: politics'\"]\n",
      "1 'ARTICLE-1: politics'\n",
      "2  'ARTICLE-2: health'\n",
      "3  'ARTICLE-3: politics'\n",
      "4  'ARTICLE-4: health'\n",
      "5  'ARTICLE-5: politics'\n",
      "6  'ARTICLE-6: politics'\n",
      "7  'ARTICLE-7: health'\n",
      "8  'ARTICLE-8: politics'\n",
      "9  'ARTICLE-9: politics'\n",
      "10  'ARTICLE-10: politics'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sh/fjb1r_5j6gxcy4lzfcc4_4zr0000gn/T/ipykernel_53131/679340383.py:31: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value ''ARTICLE-1: politics'' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[index - len(categories) + idx_category, ['Chat GPT']] = category.strip().replace(\",\", \"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "[\"'ARTICLE-1: politics'\", \" 'ARTICLE-2: politics'\", \" 'ARTICLE-3: politics'\", \" 'ARTICLE-4: politics'\", \" 'ARTICLE-5: politics'\", \" 'ARTICLE-6: entertainment and culture'\", \" 'ARTICLE-7: health'\", \" 'ARTICLE-8: environment'\", \" 'ARTICLE-9: politics'\", \" 'ARTICLE-10: politics'\"]\n",
      "11 'ARTICLE-1: politics'\n",
      "12  'ARTICLE-2: politics'\n",
      "13  'ARTICLE-3: politics'\n",
      "14  'ARTICLE-4: politics'\n",
      "15  'ARTICLE-5: politics'\n",
      "16  'ARTICLE-6: entertainment and culture'\n",
      "17  'ARTICLE-7: health'\n",
      "18  'ARTICLE-8: environment'\n",
      "19  'ARTICLE-9: politics'\n",
      "20  'ARTICLE-10: politics'\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "[\"'ARTICLE-1: politics'\", \" 'ARTICLE-2: health'\", \" 'ARTICLE-3: politics'\", \" 'ARTICLE-4: politics'\", \" 'ARTICLE-5: politics'\", \" 'ARTICLE-6: politics'\", \" 'ARTICLE-7: politics'\", \" 'ARTICLE-8: crime'\", \" 'ARTICLE-9: business and economy'\", \" 'ARTICLE-10: politics'\"]\n",
      "21 'ARTICLE-1: politics'\n",
      "22  'ARTICLE-2: health'\n",
      "23  'ARTICLE-3: politics'\n",
      "24  'ARTICLE-4: politics'\n",
      "25  'ARTICLE-5: politics'\n",
      "26  'ARTICLE-6: politics'\n",
      "27  'ARTICLE-7: politics'\n",
      "28  'ARTICLE-8: crime'\n",
      "29  'ARTICLE-9: business and economy'\n",
      "30  'ARTICLE-10: politics'\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "[\"'ARTICLE-1: politics'\", \" 'ARTICLE-2: politics'\", \" 'ARTICLE-3: environment'\", \" 'ARTICLE-4: politics'\", \" 'ARTICLE-5: politics'\", \" 'ARTICLE-6: environment'\", \" 'ARTICLE-7: health'\", \" 'ARTICLE-8: entertainment and culture'\", \" 'ARTICLE-9: environment'\", \" 'ARTICLE-10: environment'\"]\n",
      "31 'ARTICLE-1: politics'\n",
      "32  'ARTICLE-2: politics'\n",
      "33  'ARTICLE-3: environment'\n",
      "34  'ARTICLE-4: politics'\n",
      "35  'ARTICLE-5: politics'\n",
      "36  'ARTICLE-6: environment'\n",
      "37  'ARTICLE-7: health'\n",
      "38  'ARTICLE-8: entertainment and culture'\n",
      "39  'ARTICLE-9: environment'\n",
      "40  'ARTICLE-10: environment'\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "[\"'ARTICLE-1: politics'\", \" 'ARTICLE-2: politics'\", \" 'ARTICLE-3: entertainment and culture'\", \" 'ARTICLE-4: science and technology'\", \" 'ARTICLE-5: business and economy'\", \" 'ARTICLE-6: health'\", \" 'ARTICLE-7: environment'\", \" 'ARTICLE-8: politics'\", \" 'ARTICLE-9: environment'\", \" 'ARTICLE-10: entertainment and culture'\"]\n",
      "41 'ARTICLE-1: politics'\n",
      "42  'ARTICLE-2: politics'\n",
      "43  'ARTICLE-3: entertainment and culture'\n",
      "44  'ARTICLE-4: science and technology'\n",
      "45  'ARTICLE-5: business and economy'\n",
      "46  'ARTICLE-6: health'\n",
      "47  'ARTICLE-7: environment'\n",
      "48  'ARTICLE-8: politics'\n",
      "49  'ARTICLE-9: environment'\n",
      "50  'ARTICLE-10: entertainment and culture'\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "[\"'ARTICLE-1: politics'\", \" 'ARTICLE-2: economy'\", \" 'ARTICLE-3: sports'\", \" 'ARTICLE-4: entertainment'\", \" 'ARTICLE-5: politics'\", \" 'ARTICLE-6: politics'\", \" 'ARTICLE-7: entertainment'\", \" 'ARTICLE-8: health'\", \" 'ARTICLE-9: entertainment'\", \" 'ARTICLE-10: environment'\"]\n",
      "51 'ARTICLE-1: politics'\n",
      "52  'ARTICLE-2: economy'\n",
      "53  'ARTICLE-3: sports'\n",
      "54  'ARTICLE-4: entertainment'\n",
      "55  'ARTICLE-5: politics'\n",
      "56  'ARTICLE-6: politics'\n",
      "57  'ARTICLE-7: entertainment'\n",
      "58  'ARTICLE-8: health'\n",
      "59  'ARTICLE-9: entertainment'\n",
      "60  'ARTICLE-10: environment'\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "[\"'ARTICLE-1: entertainment and culture'\", \" 'ARTICLE-2: sports'\", \" 'ARTICLE-3: politics'\", \" 'ARTICLE-4: sports'\", \" 'ARTICLE-5: politics'\", \" 'ARTICLE-6: politics'\", \" 'ARTICLE-7: sports'\", \" 'ARTICLE-8: health'\", \" 'ARTICLE-9: politics'\", \" 'ARTICLE-10: entertainment and culture'\"]\n",
      "61 'ARTICLE-1: entertainment and culture'\n",
      "62  'ARTICLE-2: sports'\n",
      "63  'ARTICLE-3: politics'\n",
      "64  'ARTICLE-4: sports'\n",
      "65  'ARTICLE-5: politics'\n",
      "66  'ARTICLE-6: politics'\n",
      "67  'ARTICLE-7: sports'\n",
      "68  'ARTICLE-8: health'\n",
      "69  'ARTICLE-9: politics'\n",
      "70  'ARTICLE-10: entertainment and culture'\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "[\"'ARTICLE-1: politics'\", \" 'ARTICLE-2: politics'\", \" 'ARTICLE-3: health'\", \" 'ARTICLE-4: entertainment and culture'\", \" 'ARTICLE-5: environment'\", \" 'ARTICLE-6: entertainment and culture'\", \" 'ARTICLE-7: sports'\", \" 'ARTICLE-8: environment'\", \" 'ARTICLE-9: politics'\", \" 'ARTICLE-10: politics'\"]\n",
      "71 'ARTICLE-1: politics'\n",
      "72  'ARTICLE-2: politics'\n",
      "73  'ARTICLE-3: health'\n",
      "74  'ARTICLE-4: entertainment and culture'\n",
      "75  'ARTICLE-5: environment'\n",
      "76  'ARTICLE-6: entertainment and culture'\n",
      "77  'ARTICLE-7: sports'\n",
      "78  'ARTICLE-8: environment'\n",
      "79  'ARTICLE-9: politics'\n",
      "80  'ARTICLE-10: politics'\n",
      "81\n",
      "80 1\n",
      "81  'entertainment and culture'\n"
     ]
    }
   ],
   "source": [
    "batchSize = 10\n",
    "\n",
    "cat = {\n",
    "     1: \"politics\",\n",
    "     2: \"business and economy\",\n",
    "     3: \"environment\",\n",
    "     4: \"sports\",\n",
    "     5: \"entertainment and culture\",\n",
    "     6: \"science and technology\",\n",
    "     7: \"health\"\n",
    "    }\n",
    "\n",
    "counter = 0\n",
    "idx_lo = 0\n",
    "idx_hi = 0\n",
    "batch = \"\"\n",
    "for index, row in df.iterrows():\n",
    "    print(index)\n",
    "    if counter < batchSize:\n",
    "        title = row['Title']\n",
    "        tags = row['Tags'][1:-1]\n",
    "        counter += 1\n",
    "        batch += f\"<itemStart> ARTICLE-{counter}: Title: {title}; Tags: {tags} <itemEnd>\"\n",
    "    else:\n",
    "        categories = get_res(batch)\n",
    "        print(categories)\n",
    "        if len(categories) < 10:\n",
    "             break\n",
    "        for idx_category, category in enumerate(categories):\n",
    "            print(index + 1 - len(categories)+ idx_category, category)\n",
    "            df.loc[index - len(categories) + idx_category, ['Chat GPT']] = category.strip().replace(\",\", \"\")\n",
    "        sleep(22)\n",
    "        title = row['Title']\n",
    "        tags = row['Tags'][1:-1]\n",
    "        counter = 1\n",
    "        batch = f\"<itemStart> ARTICLE-{counter}: Title: '{title}'; Tags: {tags}] <itemEnd>\"\n",
    "\n",
    "if len(batch) > 0:\n",
    "    categories = get_res(batch)\n",
    "    for idx_category, category in enumerate(categories):\n",
    "            print(df.shape[0] - len(categories)+ idx_category, category)\n",
    "            df.loc[df.shape[0] - len(categories) + idx_category, ['Chat GPT']] = category.strip().replace(\",\", \"\")\n",
    "\n",
    "\n",
    "df.to_csv(\"2022_skynews_chatgpt_results_05.csv\", sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"2022_skynews_chatgpt_results_05.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteProtocolError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:66\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 66\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:228\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 228\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pool\u001b[39m.\u001b[39;49mhandle_request(req)\n\u001b[1;32m    230\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(resp\u001b[39m.\u001b[39mstream, typing\u001b[39m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:268\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresponse_closed(status)\n\u001b[0;32m--> 268\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n\u001b[1;32m    269\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:251\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[1;32m    252\u001b[0m \u001b[39mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    253\u001b[0m     \u001b[39m# The ConnectionNotAvailable exception is a special case, that\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     \u001b[39m# indicates we need to retry the request on a new connection.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[39m# might end up as an HTTP/2 connection, but which actually ends\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     \u001b[39m# up as HTTP/1.1.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[39mraise\u001b[39;00m ConnectionNotAvailable()\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connection\u001b[39m.\u001b[39;49mhandle_request(request)\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:133\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_response_closed()\n\u001b[0;32m--> 133\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:111\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mwith\u001b[39;00m Trace(\n\u001b[1;32m    104\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mreceive_response_headers\u001b[39m\u001b[39m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    105\u001b[0m ) \u001b[39mas\u001b[39;00m trace:\n\u001b[1;32m    106\u001b[0m     (\n\u001b[1;32m    107\u001b[0m         http_version,\n\u001b[1;32m    108\u001b[0m         status,\n\u001b[1;32m    109\u001b[0m         reason_phrase,\n\u001b[1;32m    110\u001b[0m         headers,\n\u001b[0;32m--> 111\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_response_headers(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    112\u001b[0m     trace\u001b[39m.\u001b[39mreturn_value \u001b[39m=\u001b[39m (\n\u001b[1;32m    113\u001b[0m         http_version,\n\u001b[1;32m    114\u001b[0m         status,\n\u001b[1;32m    115\u001b[0m         reason_phrase,\n\u001b[1;32m    116\u001b[0m         headers,\n\u001b[1;32m    117\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:176\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_event(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    177\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(event, h11\u001b[39m.\u001b[39mResponse):\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:226\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    225\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mServer disconnected without sending a response.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 226\u001b[0m     \u001b[39mraise\u001b[39;00m RemoteProtocolError(msg)\n\u001b[1;32m    228\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mreceive_data(data)\n",
      "\u001b[0;31mRemoteProtocolError\u001b[0m: Server disconnected without sending a response.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRemoteProtocolError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/openai/_base_client.py:866\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 866\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49msend(request, auth\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcustom_auth, stream\u001b[39m=\u001b[39;49mstream)\n\u001b[1;32m    867\u001b[0m     log\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m    868\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mHTTP Request: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m, request\u001b[39m.\u001b[39mmethod, request\u001b[39m.\u001b[39murl, response\u001b[39m.\u001b[39mstatus_code, response\u001b[39m.\u001b[39mreason_phrase\n\u001b[1;32m    869\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpx/_client.py:901\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    899\u001b[0m auth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 901\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_auth(\n\u001b[1;32m    902\u001b[0m     request,\n\u001b[1;32m    903\u001b[0m     auth\u001b[39m=\u001b[39;49mauth,\n\u001b[1;32m    904\u001b[0m     follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    905\u001b[0m     history\u001b[39m=\u001b[39;49m[],\n\u001b[1;32m    906\u001b[0m )\n\u001b[1;32m    907\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpx/_client.py:929\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 929\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_redirects(\n\u001b[1;32m    930\u001b[0m         request,\n\u001b[1;32m    931\u001b[0m         follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    932\u001b[0m         history\u001b[39m=\u001b[39;49mhistory,\n\u001b[1;32m    933\u001b[0m     )\n\u001b[1;32m    934\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpx/_client.py:966\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    964\u001b[0m     hook(request)\n\u001b[0;32m--> 966\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_single_request(request)\n\u001b[1;32m    967\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpx/_client.py:1002\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[39mwith\u001b[39;00m request_context(request\u001b[39m=\u001b[39mrequest):\n\u001b[0;32m-> 1002\u001b[0m     response \u001b[39m=\u001b[39m transport\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[1;32m   1004\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(response\u001b[39m.\u001b[39mstream, SyncByteStream)\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:227\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    215\u001b[0m req \u001b[39m=\u001b[39m httpcore\u001b[39m.\u001b[39mRequest(\n\u001b[1;32m    216\u001b[0m     method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[1;32m    217\u001b[0m     url\u001b[39m=\u001b[39mhttpcore\u001b[39m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m     extensions\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    226\u001b[0m )\n\u001b[0;32m--> 227\u001b[0m \u001b[39mwith\u001b[39;49;00m map_httpcore_exceptions():\n\u001b[1;32m    228\u001b[0m     resp \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pool\u001b[39m.\u001b[39;49mhandle_request(req)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py:155\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgen\u001b[39m.\u001b[39mthrow(typ, value, traceback)\n\u001b[1;32m    156\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    157\u001b[0m     \u001b[39m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[39m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[39m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:83\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m message \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(exc)\n\u001b[0;32m---> 83\u001b[0m \u001b[39mraise\u001b[39;00m mapped_exc(message) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[0;31mRemoteProtocolError\u001b[0m: Server disconnected without sending a response.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRemoteProtocolError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:66\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 66\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:228\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 228\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pool\u001b[39m.\u001b[39;49mhandle_request(req)\n\u001b[1;32m    230\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(resp\u001b[39m.\u001b[39mstream, typing\u001b[39m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:268\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresponse_closed(status)\n\u001b[0;32m--> 268\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n\u001b[1;32m    269\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:251\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[1;32m    252\u001b[0m \u001b[39mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    253\u001b[0m     \u001b[39m# The ConnectionNotAvailable exception is a special case, that\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     \u001b[39m# indicates we need to retry the request on a new connection.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[39m# might end up as an HTTP/2 connection, but which actually ends\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     \u001b[39m# up as HTTP/1.1.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[39mraise\u001b[39;00m ConnectionNotAvailable()\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connection\u001b[39m.\u001b[39;49mhandle_request(request)\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:133\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_response_closed()\n\u001b[0;32m--> 133\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:111\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mwith\u001b[39;00m Trace(\n\u001b[1;32m    104\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mreceive_response_headers\u001b[39m\u001b[39m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    105\u001b[0m ) \u001b[39mas\u001b[39;00m trace:\n\u001b[1;32m    106\u001b[0m     (\n\u001b[1;32m    107\u001b[0m         http_version,\n\u001b[1;32m    108\u001b[0m         status,\n\u001b[1;32m    109\u001b[0m         reason_phrase,\n\u001b[1;32m    110\u001b[0m         headers,\n\u001b[0;32m--> 111\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_response_headers(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    112\u001b[0m     trace\u001b[39m.\u001b[39mreturn_value \u001b[39m=\u001b[39m (\n\u001b[1;32m    113\u001b[0m         http_version,\n\u001b[1;32m    114\u001b[0m         status,\n\u001b[1;32m    115\u001b[0m         reason_phrase,\n\u001b[1;32m    116\u001b[0m         headers,\n\u001b[1;32m    117\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:176\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_event(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    177\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(event, h11\u001b[39m.\u001b[39mResponse):\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:226\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    225\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mServer disconnected without sending a response.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 226\u001b[0m     \u001b[39mraise\u001b[39;00m RemoteProtocolError(msg)\n\u001b[1;32m    228\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mreceive_data(data)\n",
      "\u001b[0;31mRemoteProtocolError\u001b[0m: Server disconnected without sending a response.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRemoteProtocolError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/openai/_base_client.py:866\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 866\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49msend(request, auth\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcustom_auth, stream\u001b[39m=\u001b[39;49mstream)\n\u001b[1;32m    867\u001b[0m     log\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m    868\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mHTTP Request: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m, request\u001b[39m.\u001b[39mmethod, request\u001b[39m.\u001b[39murl, response\u001b[39m.\u001b[39mstatus_code, response\u001b[39m.\u001b[39mreason_phrase\n\u001b[1;32m    869\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpx/_client.py:901\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    899\u001b[0m auth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 901\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_auth(\n\u001b[1;32m    902\u001b[0m     request,\n\u001b[1;32m    903\u001b[0m     auth\u001b[39m=\u001b[39;49mauth,\n\u001b[1;32m    904\u001b[0m     follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    905\u001b[0m     history\u001b[39m=\u001b[39;49m[],\n\u001b[1;32m    906\u001b[0m )\n\u001b[1;32m    907\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpx/_client.py:929\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 929\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_redirects(\n\u001b[1;32m    930\u001b[0m         request,\n\u001b[1;32m    931\u001b[0m         follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    932\u001b[0m         history\u001b[39m=\u001b[39;49mhistory,\n\u001b[1;32m    933\u001b[0m     )\n\u001b[1;32m    934\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpx/_client.py:966\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    964\u001b[0m     hook(request)\n\u001b[0;32m--> 966\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_single_request(request)\n\u001b[1;32m    967\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpx/_client.py:1002\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[39mwith\u001b[39;00m request_context(request\u001b[39m=\u001b[39mrequest):\n\u001b[0;32m-> 1002\u001b[0m     response \u001b[39m=\u001b[39m transport\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[1;32m   1004\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(response\u001b[39m.\u001b[39mstream, SyncByteStream)\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:227\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    215\u001b[0m req \u001b[39m=\u001b[39m httpcore\u001b[39m.\u001b[39mRequest(\n\u001b[1;32m    216\u001b[0m     method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[1;32m    217\u001b[0m     url\u001b[39m=\u001b[39mhttpcore\u001b[39m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m     extensions\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    226\u001b[0m )\n\u001b[0;32m--> 227\u001b[0m \u001b[39mwith\u001b[39;49;00m map_httpcore_exceptions():\n\u001b[1;32m    228\u001b[0m     resp \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pool\u001b[39m.\u001b[39;49mhandle_request(req)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py:155\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgen\u001b[39m.\u001b[39mthrow(typ, value, traceback)\n\u001b[1;32m    156\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    157\u001b[0m     \u001b[39m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[39m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[39m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:83\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m message \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(exc)\n\u001b[0;32m---> 83\u001b[0m \u001b[39mraise\u001b[39;00m mapped_exc(message) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[0;31mRemoteProtocolError\u001b[0m: Server disconnected without sending a response.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/niclasclassen/Desktop/chat_gpt_classification/main.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/niclasclassen/Desktop/chat_gpt_classification/main.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mchat\u001b[39m.\u001b[39;49mcompletions\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/niclasclassen/Desktop/chat_gpt_classification/main.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m         model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/niclasclassen/Desktop/chat_gpt_classification/main.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         messages\u001b[39m=\u001b[39;49m[\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/niclasclassen/Desktop/chat_gpt_classification/main.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mGenerate a high quality text about a provided topic which is the size of 2,500 words\u001b[39;49m\u001b[39m\"\u001b[39;49m},\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/niclasclassen/Desktop/chat_gpt_classification/main.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mTitle: Fun\u001b[39;49m\u001b[39m\"\u001b[39;49m}\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/niclasclassen/Desktop/chat_gpt_classification/main.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         ],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/niclasclassen/Desktop/chat_gpt_classification/main.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         temperature\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/niclasclassen/Desktop/chat_gpt_classification/main.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         max_tokens\u001b[39m=\u001b[39;49m\u001b[39m4000\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/niclasclassen/Desktop/chat_gpt_classification/main.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/niclasclassen/Desktop/chat_gpt_classification/main.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m category \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/niclasclassen/Desktop/chat_gpt_classification/main.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(response)\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/openai/_utils/_utils.py:299\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 299\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/openai/resources/chat/completions.py:598\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[39m@required_args\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    552\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    553\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    596\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m httpx\u001b[39m.\u001b[39mTimeout \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    597\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatCompletion \u001b[39m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 598\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[1;32m    599\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/chat/completions\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    600\u001b[0m         body\u001b[39m=\u001b[39;49mmaybe_transform(\n\u001b[1;32m    601\u001b[0m             {\n\u001b[1;32m    602\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmessages\u001b[39;49m\u001b[39m\"\u001b[39;49m: messages,\n\u001b[1;32m    603\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m: model,\n\u001b[1;32m    604\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfrequency_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: frequency_penalty,\n\u001b[1;32m    605\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunction_call\u001b[39;49m\u001b[39m\"\u001b[39;49m: function_call,\n\u001b[1;32m    606\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunctions\u001b[39;49m\u001b[39m\"\u001b[39;49m: functions,\n\u001b[1;32m    607\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogit_bias\u001b[39;49m\u001b[39m\"\u001b[39;49m: logit_bias,\n\u001b[1;32m    608\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_tokens,\n\u001b[1;32m    609\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mn\u001b[39;49m\u001b[39m\"\u001b[39;49m: n,\n\u001b[1;32m    610\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mpresence_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: presence_penalty,\n\u001b[1;32m    611\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mresponse_format\u001b[39;49m\u001b[39m\"\u001b[39;49m: response_format,\n\u001b[1;32m    612\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mseed\u001b[39;49m\u001b[39m\"\u001b[39;49m: seed,\n\u001b[1;32m    613\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstop\u001b[39;49m\u001b[39m\"\u001b[39;49m: stop,\n\u001b[1;32m    614\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream,\n\u001b[1;32m    615\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m\"\u001b[39;49m: temperature,\n\u001b[1;32m    616\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtool_choice\u001b[39;49m\u001b[39m\"\u001b[39;49m: tool_choice,\n\u001b[1;32m    617\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtools\u001b[39;49m\u001b[39m\"\u001b[39;49m: tools,\n\u001b[1;32m    618\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_p\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_p,\n\u001b[1;32m    619\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m: user,\n\u001b[1;32m    620\u001b[0m             },\n\u001b[1;32m    621\u001b[0m             completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParams,\n\u001b[1;32m    622\u001b[0m         ),\n\u001b[1;32m    623\u001b[0m         options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[1;32m    624\u001b[0m             extra_headers\u001b[39m=\u001b[39;49mextra_headers, extra_query\u001b[39m=\u001b[39;49mextra_query, extra_body\u001b[39m=\u001b[39;49mextra_body, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    625\u001b[0m         ),\n\u001b[1;32m    626\u001b[0m         cast_to\u001b[39m=\u001b[39;49mChatCompletion,\n\u001b[1;32m    627\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    628\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mStream[ChatCompletionChunk],\n\u001b[1;32m    629\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/openai/_base_client.py:1063\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[1;32m   1050\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1051\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1059\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m   1060\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[1;32m   1061\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[1;32m   1062\u001b[0m     )\n\u001b[0;32m-> 1063\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/openai/_base_client.py:842\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    834\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    835\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    840\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    841\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m--> 842\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m    843\u001b[0m         cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m    844\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    845\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    846\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m    847\u001b[0m         remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[1;32m    848\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/openai/_base_client.py:898\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    897\u001b[0m     \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 898\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(\n\u001b[1;32m    899\u001b[0m             options,\n\u001b[1;32m    900\u001b[0m             cast_to,\n\u001b[1;32m    901\u001b[0m             retries,\n\u001b[1;32m    902\u001b[0m             stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    903\u001b[0m             stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m    904\u001b[0m         )\n\u001b[1;32m    905\u001b[0m     \u001b[39mraise\u001b[39;00m APIConnectionError(request\u001b[39m=\u001b[39mrequest) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    907\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_response(\n\u001b[1;32m    908\u001b[0m     cast_to\u001b[39m=\u001b[39mcast_to,\n\u001b[1;32m    909\u001b[0m     options\u001b[39m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    912\u001b[0m     stream_cls\u001b[39m=\u001b[39mstream_cls,\n\u001b[1;32m    913\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/openai/_base_client.py:933\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m    930\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m    931\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[0;32m--> 933\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m    934\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    935\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m    936\u001b[0m     remaining_retries\u001b[39m=\u001b[39;49mremaining,\n\u001b[1;32m    937\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    938\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m    939\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/openai/_base_client.py:898\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    897\u001b[0m     \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 898\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(\n\u001b[1;32m    899\u001b[0m             options,\n\u001b[1;32m    900\u001b[0m             cast_to,\n\u001b[1;32m    901\u001b[0m             retries,\n\u001b[1;32m    902\u001b[0m             stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    903\u001b[0m             stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m    904\u001b[0m         )\n\u001b[1;32m    905\u001b[0m     \u001b[39mraise\u001b[39;00m APIConnectionError(request\u001b[39m=\u001b[39mrequest) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    907\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_response(\n\u001b[1;32m    908\u001b[0m     cast_to\u001b[39m=\u001b[39mcast_to,\n\u001b[1;32m    909\u001b[0m     options\u001b[39m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    912\u001b[0m     stream_cls\u001b[39m=\u001b[39mstream_cls,\n\u001b[1;32m    913\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/openai/_base_client.py:933\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m    930\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m    931\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[0;32m--> 933\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m    934\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    935\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m    936\u001b[0m     remaining_retries\u001b[39m=\u001b[39;49mremaining,\n\u001b[1;32m    937\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    938\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m    939\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/openai/_base_client.py:866\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_request(request)\n\u001b[1;32m    865\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 866\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49msend(request, auth\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcustom_auth, stream\u001b[39m=\u001b[39;49mstream)\n\u001b[1;32m    867\u001b[0m     log\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m    868\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mHTTP Request: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m, request\u001b[39m.\u001b[39mmethod, request\u001b[39m.\u001b[39murl, response\u001b[39m.\u001b[39mstatus_code, response\u001b[39m.\u001b[39mreason_phrase\n\u001b[1;32m    869\u001b[0m     )\n\u001b[1;32m    870\u001b[0m     response\u001b[39m.\u001b[39mraise_for_status()\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpx/_client.py:901\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    893\u001b[0m follow_redirects \u001b[39m=\u001b[39m (\n\u001b[1;32m    894\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfollow_redirects\n\u001b[1;32m    895\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    896\u001b[0m     \u001b[39melse\u001b[39;00m follow_redirects\n\u001b[1;32m    897\u001b[0m )\n\u001b[1;32m    899\u001b[0m auth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 901\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_auth(\n\u001b[1;32m    902\u001b[0m     request,\n\u001b[1;32m    903\u001b[0m     auth\u001b[39m=\u001b[39;49mauth,\n\u001b[1;32m    904\u001b[0m     follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    905\u001b[0m     history\u001b[39m=\u001b[39;49m[],\n\u001b[1;32m    906\u001b[0m )\n\u001b[1;32m    907\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    908\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpx/_client.py:929\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    926\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(auth_flow)\n\u001b[1;32m    928\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 929\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_redirects(\n\u001b[1;32m    930\u001b[0m         request,\n\u001b[1;32m    931\u001b[0m         follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    932\u001b[0m         history\u001b[39m=\u001b[39;49mhistory,\n\u001b[1;32m    933\u001b[0m     )\n\u001b[1;32m    934\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    935\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpx/_client.py:966\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mrequest\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    964\u001b[0m     hook(request)\n\u001b[0;32m--> 966\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_single_request(request)\n\u001b[1;32m    967\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    968\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpx/_client.py:1002\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    997\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    998\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    999\u001b[0m     )\n\u001b[1;32m   1001\u001b[0m \u001b[39mwith\u001b[39;00m request_context(request\u001b[39m=\u001b[39mrequest):\n\u001b[0;32m-> 1002\u001b[0m     response \u001b[39m=\u001b[39m transport\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[1;32m   1004\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(response\u001b[39m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1006\u001b[0m response\u001b[39m.\u001b[39mrequest \u001b[39m=\u001b[39m request\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:228\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    215\u001b[0m req \u001b[39m=\u001b[39m httpcore\u001b[39m.\u001b[39mRequest(\n\u001b[1;32m    216\u001b[0m     method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[1;32m    217\u001b[0m     url\u001b[39m=\u001b[39mhttpcore\u001b[39m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m     extensions\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    226\u001b[0m )\n\u001b[1;32m    227\u001b[0m \u001b[39mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 228\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pool\u001b[39m.\u001b[39;49mhandle_request(req)\n\u001b[1;32m    230\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(resp\u001b[39m.\u001b[39mstream, typing\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m Response(\n\u001b[1;32m    233\u001b[0m     status_code\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mstatus,\n\u001b[1;32m    234\u001b[0m     headers\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mheaders,\n\u001b[1;32m    235\u001b[0m     stream\u001b[39m=\u001b[39mResponseStream(resp\u001b[39m.\u001b[39mstream),\n\u001b[1;32m    236\u001b[0m     extensions\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    237\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:268\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[39mwith\u001b[39;00m ShieldCancellation():\n\u001b[1;32m    267\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresponse_closed(status)\n\u001b[0;32m--> 268\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n\u001b[1;32m    269\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:251\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[39mraise\u001b[39;00m exc\n\u001b[1;32m    250\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[1;32m    252\u001b[0m \u001b[39mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    253\u001b[0m     \u001b[39m# The ConnectionNotAvailable exception is a special case, that\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     \u001b[39m# indicates we need to retry the request on a new connection.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[39m# might end up as an HTTP/2 connection, but which actually ends\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     \u001b[39m# up as HTTP/1.1.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool_lock:\n\u001b[1;32m    261\u001b[0m         \u001b[39m# Maintain our position in the request queue, but reset the\u001b[39;00m\n\u001b[1;32m    262\u001b[0m         \u001b[39m# status so that the request becomes queued again.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connection\u001b[39m.\u001b[39mis_available():\n\u001b[1;32m    101\u001b[0m         \u001b[39mraise\u001b[39;00m ConnectionNotAvailable()\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connection\u001b[39m.\u001b[39;49mhandle_request(request)\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:133\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[39mwith\u001b[39;00m Trace(\u001b[39m\"\u001b[39m\u001b[39mresponse_closed\u001b[39m\u001b[39m\"\u001b[39m, logger, request) \u001b[39mas\u001b[39;00m trace:\n\u001b[1;32m    132\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_response_closed()\n\u001b[0;32m--> 133\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:111\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39mwith\u001b[39;00m Trace(\n\u001b[1;32m    104\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mreceive_response_headers\u001b[39m\u001b[39m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    105\u001b[0m ) \u001b[39mas\u001b[39;00m trace:\n\u001b[1;32m    106\u001b[0m     (\n\u001b[1;32m    107\u001b[0m         http_version,\n\u001b[1;32m    108\u001b[0m         status,\n\u001b[1;32m    109\u001b[0m         reason_phrase,\n\u001b[1;32m    110\u001b[0m         headers,\n\u001b[0;32m--> 111\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_response_headers(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    112\u001b[0m     trace\u001b[39m.\u001b[39mreturn_value \u001b[39m=\u001b[39m (\n\u001b[1;32m    113\u001b[0m         http_version,\n\u001b[1;32m    114\u001b[0m         status,\n\u001b[1;32m    115\u001b[0m         reason_phrase,\n\u001b[1;32m    116\u001b[0m         headers,\n\u001b[1;32m    117\u001b[0m     )\n\u001b[1;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m Response(\n\u001b[1;32m    120\u001b[0m     status\u001b[39m=\u001b[39mstatus,\n\u001b[1;32m    121\u001b[0m     headers\u001b[39m=\u001b[39mheaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m     },\n\u001b[1;32m    128\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:176\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    173\u001b[0m timeout \u001b[39m=\u001b[39m timeouts\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mread\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_event(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    177\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(event, h11\u001b[39m.\u001b[39mResponse):\n\u001b[1;32m    178\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:212\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    209\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mnext_event()\n\u001b[1;32m    211\u001b[0m \u001b[39mif\u001b[39;00m event \u001b[39mis\u001b[39;00m h11\u001b[39m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 212\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_network_stream\u001b[39m.\u001b[39;49mread(\n\u001b[1;32m    213\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mREAD_NUM_BYTES, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    214\u001b[0m     )\n\u001b[1;32m    216\u001b[0m     \u001b[39m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[39m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[39m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39m==\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mtheir_state \u001b[39m==\u001b[39m h11\u001b[39m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/Desktop/chat_gpt_classification/.venv/lib/python3.11/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sock\u001b[39m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv(max_bytes)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1296\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1293\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1294\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1295\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1296\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(buflen)\n\u001b[1;32m   1297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1298\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1169\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m, buffer)\n\u001b[1;32m   1168\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1169\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m)\n\u001b[1;32m   1170\u001b[0m \u001b[39mexcept\u001b[39;00m SSLError \u001b[39mas\u001b[39;00m x:\n\u001b[1;32m   1171\u001b[0m     \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m SSL_ERROR_EOF \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Generate a high quality text about a provided topic which is the size of 2,500 words\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Title: Fun\"}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=4000\n",
    "    )\n",
    "category = response.choices[0].message.content\n",
    "print(response)\n",
    "print(category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/niclasclassen/Desktop/chat_gpt_classification/main.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/niclasclassen/Desktop/chat_gpt_classification/main.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(response)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for index, row in df.iterrows():\n",
    "    print(counter)\n",
    "    title = row['Title']\n",
    "    tags = row['Tags'][1:-1]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You will be provided with a title and one or multiple tags of a news article. Your task is to classify to which of the following topics the article belongs to. The topics to choose from are: 'politics', 'business and economy', 'environment', 'sports', 'entertainment and culture', 'science and technology' or 'health'. Return only one of the provided topics and keep the same format as they are provided.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Title: '{title}'; Tags: {tags}\"}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=256\n",
    "    )\n",
    "    category = response.choices[0].message.content\n",
    "    df.loc[index, ['Chat GPT']] = category\n",
    "    sleep(5)\n",
    "    counter += 1\n",
    "\n",
    "\n",
    "df.to_csv(\"2022_skynews_chatgpt_results_03.csv\", sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
